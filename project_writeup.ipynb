{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Recognition** \n",
    "\n",
    "## Writeup\n",
    "\n",
    "### You can use this file as a template for your writeup if you want to submit it as a markdown file, but feel free to use some other method and submit a pdf if you prefer.\n",
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/visualization.jpg \"Visualization\"\n",
    "[image2]: ./examples/grayscale.jpg \"Grayscaling\"\n",
    "[image3]: ./examples/random_noise.jpg \"Random Noise\"\n",
    "[image4]: ./examples/placeholder.png \"Traffic Sign 1\"\n",
    "[image5]: ./examples/placeholder.png \"Traffic Sign 2\"\n",
    "[image6]: ./examples/placeholder.png \"Traffic Sign 3\"\n",
    "[image7]: ./examples/placeholder.png \"Traffic Sign 4\"\n",
    "[image8]: ./examples/placeholder.png \"Traffic Sign 5\"\n",
    "\n",
    "[d_exploration]: ./report-images/dataset_exploration.png \"Dataset Exploration\"\n",
    "[d_grey]: ./report-images/dataset_greyscale.png \"Dataset Greyscale\"\n",
    "[d_traslation]: ./report-images/dataset_traslation.png \"Dataset Traslation\"\n",
    "[d_rotation]: ./report-images/dataset_rotation.png \"Dataset Rotation\"\n",
    "[d_blur]: ./report-images/dataset_blurred.png \"Dataset Blur\"\n",
    "[d_equalization]: ./report-images/dataset_equalization.png \"Dataset Equalization\"\n",
    "[d_distribution]: ./report-images/distribution_of_classes.png \"Distribution of Classes\"\n",
    "[predictions]: ./report-images/predictions.jpg \"Downloaded signs predictions\"\n",
    "[featuremap]: ./report-images/feature_map.jpg \"Feature maps\"\n",
    "\n",
    "[sign1]: ./extra-signs/1.jpg \"Speed limit 30km/h\"\n",
    "[sign2]: ./extra-signs/9.jpg \"No passing\"\n",
    "[sign3]: ./extra-signs/12a.jpg \"Priority road\"\n",
    "[sign4]: ./extra-signs/14.jpg \"Stop\"\n",
    "[sign5]: ./extra-signs/23a.jpg \"Slippery road\"\n",
    "[sign6]: ./extra-signs/28a.jpg \"Children crossing\"\n",
    "[sign7]: ./extra-signs/4.jpg \"Speed limit 70km/h\"\n",
    "\n",
    "\n",
    "## Rubric Points\n",
    "### Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/481/view) individually and describe how I addressed each point in my implementation.  \n",
    "\n",
    "---\n",
    "### Writeup / README\n",
    "\n",
    "You're reading it! and here is a link to my [project code](https://github.com/MC-8/SDC-P2-traffic-signs/blob/master/Traffic_Sign_Classifier.ipynb)\n",
    "\n",
    "### Data Set Summary & Exploration\n",
    "\n",
    "I used the pandas library to calculate summary statistics of the traffic\n",
    "signs data set:\n",
    "\n",
    "* The size of training set is 34799\n",
    "* The size of the validation set is 4410\n",
    "* The size of test set is 12630\n",
    "* The shape of a traffic sign image is (32, 32, 3)\n",
    "* The number of unique classes/labels in the data set is 43\n",
    "\n",
    "Here is an exploratory visualization of the data set. The following image displays a sample of images present in the dataset. It can be noticed that the pictures, despite having the same resolution, have different quality. Some of them are easy (for a human) to identify while require a bit of eye-squeezing and imagination, due to lighting conditions, blur, etc.\n",
    "![alt text][d_exploration]\n",
    "\n",
    "The second image shows a normalized distribution of the classes in the three dataset. \n",
    "![alt text][d_distribution]\n",
    "\n",
    "It can be noted that training, validation and test datasets have very similar distributions, which is a positive characteristic as the training, validation and set will be done under similar conditions. However, the low-representation of some classes may lead to less precise results. Data augmentation will is in this report employed to increase the number of images in the training set, which should increase the accuracy of our neural network.\n",
    "\n",
    "\n",
    "### Design and Test a Model Architecture\n",
    "\n",
    "When using images to train a neural network, there are at least a couple of consideration to do.\n",
    "First, it is desirable to have quality images. Since this is not possible in the real world, it is more desirable to have a network that can recognize traffic signs even if the conditions are not so good. For examples, lighting conditions, blur caused by speed or fog,  and different viewing angles have all an significant impact on how well can we recognize a sign. \n",
    "Second, to facilitate the learning process, it may be helpful to reduce the complexity of the images in order for the network to discern important features and not be \"distracted\" by unnecessary features. For example, even if the color of traffic signs are distinctive of their tipology, is very well possible to correctly classify a sign even when the images is in greyscale.\n",
    "\n",
    "In practice, converting images to greyscale achieves slight better accuracy. \n",
    "Here is an example of what the dataset looks like after applying a greyscale transformation.\n",
    "\n",
    "![alt text][d_grey]\n",
    "\n",
    "Due to the low amount of samples for some classes in the training set, I've decided to augment the dataset with random copies of images in the training dataset, but modified with some image processing algorithm. This way, an image with applied some digital filtering, is effectively a new image that can improve our network accuracy because it can add another \"real-world\" condition for our traffic sign.\n",
    "\n",
    "Some image processing techniques (in addition to greyscale) that were considered (and are not limited to):\n",
    "* Blurring\n",
    "* Rotation\n",
    "* Traslation\n",
    "\n",
    "Here are example of the database after blur, rotation and translation are applied to random images in the dataset.\n",
    "\n",
    "__Dataset sample with blurred images__\n",
    "![alt text][d_blur]\n",
    "A gaussian filter with random size beween 1 and 5 is applied to random images, and the result appended to the dataset.\n",
    "\n",
    "__Dataset sample with rotated images__\n",
    "![alt text][d_rotation]\n",
    "A random rotation between -15 and 15 degrees is applied to random images, and the result appended to the dataset.\n",
    "\n",
    "__Dataset sample with traslated images__\n",
    "![alt text][d_traslation]\n",
    "A random traslation up to 8 pixels in any direction is applied to random images, and the result appended to the dataset.\n",
    "\n",
    "There are many other image processing techniques, such as warping and image flipping, that can be used. Since I obtained good results with the few techniques described, I decided to not implement more.\n",
    "\n",
    "Additionally, I've experimented with histogram equalization, which is a technique that makes lighting and colors of the images more even across the dataset.\n",
    "An example of an equalized dataset looks like this:\n",
    "\n",
    "![alt text][d_equalization]\n",
    "\n",
    "This was to test my assumption that images that an even dataset (from lighting point of view) reduces the number of features that the network should detect (a dark sign is the same as a bright sign). In practice, even if there is a slight improvement, I have not found significant gain over the training performed with the greyscale dataset.\n",
    "\n",
    "The last step before feeding images to our network is to normalize the image data. Each pixel per channel has normally a value in [0, 255] but in order to improve the numerical accuracy of the learning algorithm, it is good practice to normalize data using a floating point reprensetation that maps the integer [0, 255] range to a floating point range of [-1, 1]. \n",
    "\n",
    "\n",
    "#### Network architecture\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 3x3     \t| 1x1 stride, same padding, outputs 32x32x8 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Convolution 3x3     \t| 1x1 stride, same padding, outputs 32x32x32 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Convolution 3x3     \t| 1x1 stride, same padding, outputs 32x32x64 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 16x16x64 \t\t\t\t|\n",
    "| Fully connected\t\t| outputs 256        \t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| Keep probability = 90%\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 128        \t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| outputs 64        \t\t\t\t\t\t\t|\n",
    "| Classifier\t\t\t| 43 classes        \t\t\t\t\t\t\t|\n",
    " \n",
    "#### Model training\n",
    "\n",
    "To train the model, I shuffled the image/label pairs, set a number of epochs of 50, and a batch size of 100.\n",
    "An Adam optimizer with learning rate of 0.001 is a typical choice. The Adam optimizer is a more complex optimizer than the classic gradient descent, and it is well known in literature to produce good results in shorter time with respect to other optimizers. I experimented different learning rates and batch sizes, and this combination of hyperparameters achieved very good results.\n",
    "\n",
    "#### Approach used to achieve the target validation accuracy\n",
    "\n",
    "My final model results were:\n",
    "* validation set accuracy of __98.2%__\n",
    "* test set accuracy of __95.3%__\n",
    "\n",
    "This is well above the assignment target of 93% and while it is not acceptable for real-world applications, it is a satisfactory result obtained at this stage while I am learnig several concepts in neural networks.\n",
    "\n",
    "If an iterative approach was chosen:\n",
    "The LeNet network was chosen as a starting point because it already accepts 32x32 and achieves a decent accuracy (88%) with traffic signs (even if it was not designed for that). LeNet works well with digits, but traffic signs have many more features than hand written digits, hence it was decided to adapt this network architecture, rather than build a network from scratch.\n",
    "I tried several approaches:\n",
    "* Increasing the number/size of convolutional layers\n",
    "* Increasing the number/size of fully connected layers\n",
    "* Add drop-out layers\n",
    "\n",
    "Convolutional layers are very important when images are spatially correlated: traffic signs have many straight lines curves and there is a high correlation across adjacent pixels.\n",
    "The use of drop-out layers helps to robustify the network and reduce overfitting.\n",
    "98% of validation accuracy is a fairly good result for this exercise, definitely not for real-world applications, but from there, it is challenging to improve the accuracy by simply adding/reducing layers. Not only that, it was found that data augmentation was pivotal for increasing the accuracy above 93%: improving the quality/quantity/variety of the training set should boost the accuracy as well.\n",
    "The test accuracy of 95.3% proves that the model is not overfitting, or at least it is robust enough to handle new data.\n",
    "This will be further demostrated when testing the model on new images, as described in the next section.\n",
    " \n",
    "\n",
    "### Test a Model on New Images\n",
    "\n",
    "Here are seven traffic signs that I found on the web:\n",
    "\n",
    "![alt text][sign1] ![alt text][sign2] ![alt text][sign3] \n",
    "![alt text][sign4] ![alt text][sign5] ![alt text][sign6] ![alt text][sign7]\n",
    "\n",
    "The second image might be difficult to classify because there are two traffic signs in the same image. All the images were resized to 32x32 pixels and saved in jpg format. These images were fed to the network, which would classify them and calculate the accuracy based on labels I manually assigned them.\n",
    "\n",
    "Here are the results of the prediction, where the second image was labelled as \"No passing\" because that is the sign closer to the observer point of view:\n",
    "\n",
    "| Image\t\t\t        |     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Speed Limit 30km/h      \t\t| Speed Limit 30km/h\t\t\t\t\t| \n",
    "| No passing     \t\t\t| No passing\t\t\t\t|\n",
    "| Priority road\t\t\t\t\t|Priority road\t\t\t\t\t|\n",
    "| Stop\t      \t\t| Stop\t      \t\t\t\t|\n",
    "| Slippery Road\t\t\t| Slippery Road\t\t\t|\n",
    "| Children crossing\t\t\t| Children crossing\t\t\t\t|\n",
    "| Speed Limit 70km/h\t\t\t| Speed Limit 70km/h\t\t\t\t|\n",
    "\n",
    "\n",
    "The model was able to correctly guess 7 of the 7 traffic signs, which gives an accuracy of 100%. This is an ideal situation, but running the validation on this data set multiple times produced oscillating results between 5/7 and 7/7 images classified correctly. Some of the signs, in fact, are not always correctly classified. The speed limit 30km/h is sometimes classified as 70km/h speed limit, and the slippery road is sometimes classified as bycicle crossing.\n",
    "\n",
    "The code for making predictions on my final model is located at the end of Step 3 in the Python notebook.\n",
    "A visualization of the softmax probabilities is in the following image:\n",
    "![alt text][predictions]\n",
    "\n",
    "For all images except the first one the network is quite sure of its prediction (the numerical probability >99.999%).\n",
    "For the 30km/s limit there is, as discussed earlier, significant chance (about 15%) that the sign is a 70km/h for the network. This may cause the autonomous car to get quite a speeding ticket!\n",
    "\n",
    "### Visualizing the Neural Network\n",
    "The feature map of the three convolutional network is shown in the following picture. From top to bottom the first to the third convolutional layers feature maps are shown.\n",
    "\n",
    "![alt text][featuremap]\n",
    "\n",
    "It can be noted that from the first layer, the distinctive features of the traffic signs are immediately picked up, like the round shape, the inner and outer edges, and the numbers 3 and 0. The second layer add a bit more details on the sign, while the last layer looks like a sparse set of random pixels.\n",
    "Normally I would have expected the high level features to appear on later layers, but perhaps the traffic signs are actually simple enough for the network to pick up all the relevant features within the first two layers. Indeed, removing the last layer achieved lower accuracy, so there may be patterns in the 30km/h traffic sign that we, mere humans, cannot comprehend.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "688px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
